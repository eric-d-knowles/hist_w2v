{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c8750c1-c3df-492e-b942-d06b355ae6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%load_ext autoreload\n",
    "\n",
    "%autoreload 2\n",
    "\n",
    "os.chdir('/scratch/edk202/hist_w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85d0db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755148249.410853  639809 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755148249.416276  639809 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755148249.430396  639809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755148249.430411  639809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755148249.430413  639809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755148249.430414  639809 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    }
   ],
   "source": [
    "import orjson\n",
    "import rocksdict\n",
    "\n",
    "from ngram_tools.download_and_ingest_to_rocksdb import download_and_ingest_to_rocksdb\n",
    "from reservoir_sampler_python import reservoir_sampling_python\n",
    "from utils.resource_summary import print_resource_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5fff30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python setup.py clean --all\n",
    "!python setup.py build_ext --inplace --force\n",
    "\n",
    "# Reload the optimized modules\n",
    "from src.reservoir_sampler import reservoir_sampling\n",
    "from src.count_db_items import count_db_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91dc439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<pre>SYSTEM RESOURCE SUMMARY\n",
       "=============================================\n",
       "Hostname: cm047.hpc.nyu.edu\n",
       "\n",
       "Job Allocation:\n",
       "   CPUs: 40\n",
       "   Memory: 293.0 GB\n",
       "   Partition: short\n",
       "   Job ID: 64944309\n",
       "   Node list: cm047\n",
       "\n",
       "Physical GPU Hardware:\n",
       "   No physical GPUs allocated to this job\n",
       "\n",
       "TensorFlow GPU Recognition:\n",
       "   TensorFlow can access 0 GPU(s)\n",
       "   Built with CUDA support: True\n",
       "=============================================</pre>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print_resource_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bf72e9",
   "metadata": {},
   "source": [
    "# Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582cab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mStart Time: 2025-08-14 01:02:33.212120\n",
      "\u001b[0m\n",
      "\u001b[4mDownload & Ingestion Configuration\u001b[0m\n",
      "Ngram repository:           https://storage.googleapis.com/books/ngrams/books/20200217/eng/eng-5-ngrams_exports.html\n",
      "RocksDB database path:      /vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\n",
      "File index range:           0 to 19422\n",
      "Total files available:      19423\n",
      "Files to process:           12816\n",
      "First file URL:             https://storage.googleapis.com/books/ngrams/books/20200217/eng/5-14825-of-19423.gz\n",
      "Last file URL:              https://storage.googleapis.com/books/ngrams/books/20200217/eng/5-16116-of-19423.gz\n",
      "Ngram size:                 5\n",
      "Ngram filtering:            tagged\n",
      "Overwrite mode:             False\n",
      "Files to skip (processed):  6607\n",
      "Worker processes/threads:   16 (processes)\n",
      "Write batch size:           20,000,000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Files:   1%|\u001b[34m‚ñè         \u001b[0m| 174/12816 [05:10<94:02:23, 26.78s/files]"
     ]
    }
   ],
   "source": [
    "proj_dir = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/\"\n",
    "db_path = os.path.join(proj_dir, \"5grams.db\")\n",
    "\n",
    "download_and_ingest_to_rocksdb(\n",
    "    ngram_size=5,\n",
    "    ngram_type='tagged',\n",
    "    repo_release_id=\"20200217\",\n",
    "    repo_corpus_id=\"eng\",\n",
    "    db_path=db_path,\n",
    "    #file_range=(0, 999),\n",
    "    workers=16,\n",
    "    write_batch_size=20000000,\n",
    "    use_threads=False,\n",
    "    overwrite=False,\n",
    "    random_seed=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ebff105",
   "metadata": {},
   "source": [
    "# Inspect Database Contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad1f2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\"\n",
    "db = rocksdict.Rdict(db_path)\n",
    "\n",
    "import struct\n",
    "\n",
    "# Request (key, value) tuples now that value payload is packed binary\n",
    "sample = reservoir_sampling(\n",
    "    db,\n",
    "    sample_size=10,\n",
    "    key_type=\"string\",\n",
    "    progress_interval=100_000_000,\n",
    "    max_items=2_500_000_000,\n",
    "    return_keys=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nSAMPLE\")\n",
    "print(\"-\"*60)\n",
    "for i, item in enumerate(sample[:len(sample)], 1):\n",
    "    key, value = item\n",
    "    # Unpack binary value: each record is (year, match_count, volume_count) as uint32\n",
    "    freq_tuples = struct.iter_unpack('<III', value)\n",
    "    print(f\"{i}. {key}\")\n",
    "    for j, (year, match_count, volume_count) in enumerate(freq_tuples, 1):\n",
    "        print(f\"    {j}: year={year}, match_count={match_count}, volume_count={volume_count}\")\n",
    "\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e36229",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\"\n",
    "db = rocksdict.Rdict(db_path)\n",
    "\n",
    "import struct\n",
    "\n",
    "sample = reservoir_sampling_python(\n",
    "    db,\n",
    "    sample_size=10,\n",
    "    key_type=\"string\",\n",
    "    progress_interval=100_000_000,\n",
    "    max_items=2_500_000_000,\n",
    "    return_keys=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nSAMPLE (Python)\")\n",
    "print(\"-\"*60)\n",
    "for i, item in enumerate(sample[:len(sample)], 1):\n",
    "    key, value = item\n",
    "    freq_tuples = struct.iter_unpack('<III', value)\n",
    "    print(f\"{i}. {key}\")\n",
    "    for j, (year, match_count, volume_count) in enumerate(freq_tuples, 1):\n",
    "        print(f\"    {j}: year={year}, match_count={match_count}, volume_count={volume_count}\")\n",
    "\n",
    "db.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a925760a",
   "metadata": {},
   "outputs": [],
   "source": [
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be665f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"/vast/edk202/NLP_corpora/Google_Books/20200217/eng/5gram_files/5grams.db\"\n",
    "db = rocksdict.Rdict(db_path)\n",
    "\n",
    "count = count_db_items(db, progress_interval=100_000_000)\n",
    "\n",
    "db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ac8d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine the unpacked binary structure of one sample (value payload is packed frequencies)\n",
    "import struct\n",
    "\n",
    "if sample:\n",
    "    print(\"Sample unpacked structure:\")\n",
    "    print(\"=\"*50)\n",
    "    key, value = sample[-1]\n",
    "    freq_tuples = list(struct.iter_unpack('<III', value))\n",
    "    print(f\"Key: {key}\")\n",
    "    print(f\"Number of frequency records: {len(freq_tuples)}\")\n",
    "    print(\"Frequencies (first 5 shown):\")\n",
    "    for freq in freq_tuples[:5]:\n",
    "        year, match_count, volume_count = freq\n",
    "        print(f\"  year={year}, match_count={match_count}, volume_count={volume_count}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Remote kernel: hist_w2v",
   "language": "python",
   "name": "hist_w2v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
